# import basic libs

# import 3rd party libs
from transformers import pipeline # or Auto{**}

# import  sister modules

# instantiate all hugging face models
llama = pipeline("text-generation", model="meta-llama/Llama-2-7b-chat-hf")

# define a class to handle end-to-end processing for VisuaLlama
def endtoend(self, text_generation_model, image_recog_model, ):
    """
    
    """

# 
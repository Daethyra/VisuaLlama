[project]
name = "VisuaLlama"
version = "v0.3"
description = "A conversational, object-counting assistant."
authors = [
    {name = "Daethyra (Daemon Carino)", email = "dev-daethyra@protonmail.com"},
]
requires-python = ">=3.8,<3.11"
license = {text = "GNU AGPL"}
dependencies = [
    "Pillow",
    "requests",
    "gradio",
    "numpy",
    "matplotlib",
    "transformers",
    "tensorflow>=2.13.0",
    "tensorflow-io-gcs-filesystem==0.23.1",
    "tensorboard",
    "torch",
    "torchvision",
    "ngrok @ https://bin.equinox.io/c/${NGROK_API_KEY}:${NGROK_AUTHTOKEN}@bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz"
]
readme = "README.md"
classifiers = [
    "Development Status :: v0.3 - Alpha",
    "Intended Audience :: Non-technical Users, Developers",
    "License :: OSI Approved :: Affero GNU GPL v3.0",
    "Topic :: VQA, Llama",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
]

[project.scripts]
pdm = "pdm.core:main"

[build-system]
requires = ["pdm-backend"]
build-backend = "pdm.backend"